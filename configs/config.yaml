dataset:
  dataset_name: 'ECG5000'
  in_channels: 1
  data_scaling: True
  batch_sizes:
    vqvae: 128
  num_workers: 16

model_params:
  LR: 0.001 #0.01
  weight_decay: 0.001 #0.00001

trainer_params:
  gpus:
    - 0
  max_epochs:
    vqvae: 1500
    barlowvqvae: 1500

encoder:
  dim: 64
  dropout_rate: 0.0
  n_resnet_blocks: 4
  downsampled_width: 8

decoder:
  dim: 64
  dropout_rate: 0.0
  n_resnet_blocks: 4

VQVAE:
  n_fft: 8
  codebook:
    size: 32
    dim: 64
  decay: 0.8
  commitment_weight: 1
  emb_dropout: 0.
  perceptual_loss_weight: 0

TBE_VQVAE:
#inherites parameters from VQVAE
  SSL_loss_weight: 1

  augmentations:
    used_augmentations:
      - 'jitter'
      - 'AmpR'
      - 'STFT'
      - 'slope'
      - 'jitter'
    AmpR_rate: 0.1
    slope_rate: 0.01
    jitter_std: 0.01
    n_fft: 2048 #for STFT augmentation

barlow_twins:
  proj_hid: 4096 #projector hidden layer size
  proj_out: 4096 #projector output layer size
  loss:
    lambda: 0.005

vicreg:
  proj_hid: 4096 #projector hidden layer size
  proj_out: 4096 #projector output layer size
  loss:
    lambda: 25   # sim_loss
    mu: 25       # var_loss
    nu: 1        # cov_loss

MaskGIT:
  choice_temperatures: # for masking
    lf: 4
    hf: 4
  stochastic_sampling: 1  # from (Lee et al., 2022)
  T: 10
  prior_model:
    hidden_dim: 256
    n_layers: 4
    heads: 2
    ff_mult: 1
    use_rmsnorm: True
    p_unconditional: 0.2
  ESS:
    use: False
    error_ratio_ma_rate: 0.3

representations:
  test_stage1: True
  test_stage2: False
